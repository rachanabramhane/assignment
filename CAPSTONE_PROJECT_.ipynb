{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachanabramhane/assignment/blob/main/CAPSTONE_PROJECT_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name - Rachana Bramhane\n",
        "\n",
        "Capstone Project - CT scan image classification"
      ],
      "metadata": {
        "id": "4Q9lNJB3dLKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This example will show the steps needed to build a 3D convolutional neural network (CNN) to predict the presence of viral pneumonia in computer tomography (CT) scans. 2D CNNs are commonly used to process RGB images (3 channels). A 3D CNN is simply the 3D equivalent: it takes as input a 3D volume or a sequence of 2D frames (e.g. slices in a CT scan), 3D CNNs are a powerful model for learning representations for volumetric data.**\n"
      ],
      "metadata": {
        "id": "w3eQ6jvxdWkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcWS-Q66d8q-"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of lung CT scans with COVID-19 related findings, as well as without such findings.\n",
        "\n",
        "We will be using the associated radiological findings of the CT scans as labels to build a classifier to predict presence of viral pneumonia. Hence, the task is a binary classification problem."
      ],
      "metadata": {
        "id": "mf_7kPN3dl9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qZzXhjztdJ6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TR0uB7HPpWpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data and preprocessing\n",
        " CT scans store raw voxel intensity in Hounsfield units (HU). They range from -1024 to above 2000 in this dataset. Above 400 are bones with different radiointensity, so this is used as a higher bound. A threshold between -1000 and 400 is commonly used to normalize CT scans.\n",
        "\n",
        "To process the data, we do the following:\n",
        "\n",
        "We first rotate the volumes by 90 degrees, so the orientation is fixed\n",
        "We scale the HU values to be between 0 and 1.\n",
        "We resize width, height and depth.\n",
        "Here we define several helper functions to process the data. These functions will be used when building training and validation datasets"
      ],
      "metadata": {
        "id": "Tzhc6SOUd95p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=[]\n",
        "label=[]\n",
        "for i in glob.glob('/content/drive/MyDrive/capstone_project/'+'*/*.png'):\n",
        "  path.append(i)\n",
        "  label.append(i.split('/')[-2])"
      ],
      "metadata": {
        "id": "bWQTGl9w4E_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "id": "udmrzVbg4rID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\"Path\":path,\"Label\":label})\n",
        "data"
      ],
      "metadata": {
        "id": "ghvdXLZN4tXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Label'].value_counts()"
      ],
      "metadata": {
        "id": "QbyHQH-ceTV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_data=data.sample(frac=1)"
      ],
      "metadata": {
        "id": "lF24Q2f7L2N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Flatten,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "n8J-I_6khZsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping"
      ],
      "metadata": {
        "id": "ZD_DOI-ThyXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation\n",
        "The CT scans also augmented by rotating at random angles during training. Since the data is stored in rank-3 tensors of shape (samples, height, width, depth), we add a dimension of size 1 at axis 4 to be able to perform 3D convolutions on the data. The new shape is thus (samples, height, width, depth, 1). There are different kinds of preprocessing and augmentation techniques out there, this example shows a few simple ones to get started."
      ],
      "metadata": {
        "id": "N0AccV8geamB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "oboe5lv3uCbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")"
      ],
      "metadata": {
        "id": "q22jhUcpy2Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_data['Label'] = master_data['Label'].replace({\"COVID\":0,\"non-COVID\":1})"
      ],
      "metadata": {
        "id": "N-Br6j3VBFOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_data['Label'].unique()"
      ],
      "metadata": {
        "id": "M1uwB9AoCCKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_data.head(2)"
      ],
      "metadata": {
        "id": "m0w_6fpSC1KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=master_data,\n",
        "    x_col='Path',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "id": "jgf9__38CNso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=master_data,\n",
        "    x_col='Path',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "hQ625hOrMngS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "pFHmvit3TZwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import The Libraries \n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Z7-3MpWJTj51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path= []\n",
        "label = []\n",
        "for i in glob('/content/drive/MyDrive/capstone_project'+'*/*.png'):\n",
        "    path.append(i)\n",
        "    label.append(i.split('/')[-2])"
      ],
      "metadata": {
        "id": "YDo0QNUIToYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fcMOhhIMT6Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path\n",
        "capstone_project=(\"/content/drive/MyDrive/capstone_project\")\n",
        "covid_path=(\"/content/drive/MyDrive/capstone_project/covid\")\n",
        "noncovid_path=(\"/content/drive/MyDrive/capstone_project/noncovid\")"
      ],
      "metadata": {
        "id": "mgLU1nuGUKKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Resize variable\n",
        "IMAGE_SIZE = [224, 224] # This is my desired image size... and also ResNet50 accepts image of 224*224."
      ],
      "metadata": {
        "id": "SR-3G_2MUqFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet-50 is a convolutional neural network that is 50 layer deep. we can load a pretrained version of the network trained on more than a million images from rhe imagenet database. "
      ],
      "metadata": {
        "id": "gd0kPWDDCzI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet50(\n",
        "    input_shape = IMAGE_SIZE + [3], # Making the image into 3 Channel, so concating 3.\n",
        "    weights = 'imagenet', # Default weights.\n",
        "    include_top = False   # \n",
        ")"
      ],
      "metadata": {
        "id": "hsmJ2xXkUuqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.summary()"
      ],
      "metadata": {
        "id": "-95IyyLmU6Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = True  "
      ],
      "metadata": {
        "id": "wEV05bYeVOIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob(\"/content/drive/MyDrive/capstone_project\" + '/*')\n",
        "folders"
      ],
      "metadata": {
        "id": "xTk-x4p6VTB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(folders)"
      ],
      "metadata": {
        "id": "XtZk040EWXdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capstone_project_label = ['covid','noncovid']"
      ],
      "metadata": {
        "id": "I5jv02LXWc68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(resnet.output)"
      ],
      "metadata": {
        "id": "qP6L12k1WxZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(folders)"
      ],
      "metadata": {
        "id": "hqWPPXV2W1Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(len(folders), activation = 'softmax')(x)"
      ],
      "metadata": {
        "id": "fSP9S7O_W47H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.input"
      ],
      "metadata": {
        "id": "xtdjcr0IW-Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model Object\n",
        "model = Model(inputs = resnet.input, outputs = prediction)"
      ],
      "metadata": {
        "id": "MG4nWp5hXC0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the model accuracy and loss for the training and the validation sets are plotted. Since the validation set is class-balanced, accuracy provides an unbiased representation of the model's performance."
      ],
      "metadata": {
        "id": "vN4g6_R-u1CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aaJIp42-XG2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile (\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "11m6CN0OXM-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = 1010\n",
        "batch_size = 64\n",
        "img_size = 200\n",
        "nb_epochs = 30"
      ],
      "metadata": {
        "id": "65gbwhLMAf5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1./255, \n",
        "    validation_split=0.25,\n",
        "    horizontal_flip = True,    \n",
        "    zoom_range = 0.3,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range=0.3\n",
        "    )\n",
        "\n",
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "    dataframe=master_data,\n",
        "    directory=\"/content/drive/MyDrive/capstone_project\",\n",
        "    x_col=\"Path\",\n",
        "    y_col=\"Label\",\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",    \n",
        "    target_size=(img_size,img_size))"
      ],
      "metadata": {
        "id": "K-_ejX1p-6TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "    dataframe=master_data,\n",
        "    directory=\"/content/drive/MyDrive/capstone_project\",\n",
        "    x_col=\"Path\",\n",
        "    y_col=\"Label\",\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",    \n",
        "    target_size=(img_size,img_size))"
      ],
      "metadata": {
        "id": "uTQcfggICO_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ec0doKrcAGjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = 'new_model.h5'\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path,save_best_only=True)"
      ],
      "metadata": {
        "id": "ue-xS2EBAK14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EarlyStopping = tf.keras.callbacks.EarlyStopping(patience=4)"
      ],
      "metadata": {
        "id": "56c3erLXAMEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data = test_generator,\n",
        "    epochs = 10,\n",
        "    steps_per_epoch = len(train_generator),\n",
        "    validation_steps = len(test_generator)\n",
        ")             "
      ],
      "metadata": {
        "id": "P4yV6y93ajWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that the number of samples is very small (only 200) and we don't specify a random seed. As such, you can expect significant variance in the results. The full dataset which consists of over 1000 CT scans can be found. Using the full dataset, an accuracy of 90% was achieved. A variability of 5-6% in the classification performance is observed in both cases."
      ],
      "metadata": {
        "id": "GPYaQetICVuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions on a single CT scan"
      ],
      "metadata": {
        "id": "_WC-ChfSCHS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(test_generator)"
      ],
      "metadata": {
        "id": "0hKFyr1-bM3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "AGuv2IzbXUAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(prediction, axis = 1)"
      ],
      "metadata": {
        "id": "5eqRDC8eAf3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = np.argmax(prediction, axis = 1)\n",
        "prediction"
      ],
      "metadata": {
        "id": "sSiAxt99AoSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}